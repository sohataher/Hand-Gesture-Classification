# Hand Gesture Classification Using MediaPipe Landmarks from the HaGRID Dataset

## Project Overview
This project focuses on classifying hand gestures using landmark data generated by **MediaPipe** from the **HaGRID (Hand Gesture Recognition Image Dataset)**. The goal is to create a machine learning model capable of recognizing various hand gestures by analyzing keypoints (x, y, z coordinates) extracted from images or videos.

## Dataset
The **HaGRID** dataset contains **18 distinct hand gestures**, each represented by a set of **21 hand landmarks**. These landmarks are extracted using **MediaPipe** and are provided in a CSV format. Each entry in the CSV file includes the 3D coordinates (x, y, z) of the hand landmarks along with the corresponding gesture label.

## Project Workflow

### 1. Data Loading
- The dataset is loaded from a CSV file containing the hand landmarks and corresponding gesture labels.

### 2. Data Preprocessing
- **Cleaning**: Raw data is cleaned to remove any missing or irrelevant information.
- **Normalization**: The hand landmarks are normalized relative to the **mid-fingertip**. This step rescales the x, y coordinates of the landmarks, making the data invariant to hand size and position, thereby enhancing model robustness across different hand gestures.

### 3. Feature Selection
- Relevant features are selected to improve model performance and reduce complexity.

### 4. Model Training
- Multiple machine learning models are trained, including:
  - **K-Nearest Neighbors (KNN)**
  - **Support Vector Machine (SVM)**
  - **Random Forest (RF)**
  - **XGBoost**
- **XGBoost** emerged as the top performer, achieving an accuracy of approximately **98%**.

### 5. Hyperparameter Tuning
- A **Random Search** technique is applied to fine-tune the hyperparameters of the XGBoost model for better performance.

### 6. Model Evaluation
- Models are evaluated using the following performance metrics:
  - **Accuracy**
  - **Precision**
  - **Recall**
  - **F1-Score**

### 7. Testing
- The trained model is tested on images, real-time hand gesture recognition using a **webcam** and also evaluated on **pre-recorded videos** to assess its performance in real-world scenarios.

## Requirements

### Software
- **Python 3.x**

### Libraries
- `pandas`
- `numpy`
- `matplotlib`
- `seaborn`
- `scikit-learn`
- `xgboost`
- `mediapipe`

## Conclusion
This project demonstrates how to use **MediaPipe** for hand gesture classification using machine learning models. The **XGBoost** model, after hyperparameter optimization, delivers excellent performance, making it suitable for real-time applications in hand gesture recognition.